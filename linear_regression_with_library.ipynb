{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae6ceb7-e252-47ec-9cd4-2202b408e5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a2ac2c-d901-4bca-a478-ebe98fb342cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = utils.load_csv_data('<local-path>/data/Advertising.csv')\n",
    "\n",
    "feature_keys = ['tv', 'radio', 'newspaper']\n",
    "target_key = 'sales'\n",
    "\n",
    "X, y = utils.prepare_data(raw_data, feature_keys, target_key)\n",
    "\n",
    "print(\"X Shape: \", X.shape)\n",
    "print(\"X length: \", len(X))\n",
    "print(\"X first 5 features: \", X[:5])\n",
    "print(\"X type: \", type(X))\n",
    "\n",
    "print(\"y Shape: \", y.shape)\n",
    "print(\"y length: \", len(y))\n",
    "print(\"y first 5 features: \", y[:5])\n",
    "print(\"y type: \", type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658e2a6f-7e3a-4207-bc85-f1e0f234050e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first 5 features vs target\n",
    "print(\"Plot first 5 X vs y\")\n",
    "utils.plot_features_vs_target(X[:5], y[:5], feature_keys, target_key)\n",
    "\n",
    "# Plot the entire features vs target\n",
    "print(\"Plot entire X vs y\")\n",
    "utils.plot_features_vs_target(X, y, feature_keys, target_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda76f85-0ab4-4615-a27b-0b69292efe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Split the dataset into training, validation, and test sets\n",
    "# First split: 75% training, 25% temporary set\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.25, random_state=55)\n",
    "# Second split: Divide the temporary set into validation and test sets (50% each, which is 12.5% of the original data each)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.50, random_state=55)\n",
    "\n",
    "# Step 2: Normalize using TensorFlow (adapt on train only)\n",
    "# Create a normalization layer that will standardize the features\n",
    "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "# Fit the normalizer only on training data to avoid data leakage\n",
    "normalizer.adapt(X_train)  # Only fit on training data\n",
    "\n",
    "# Step 3: Transform all datasets using the fitted normalizer\n",
    "# Apply normalization to training data and convert to numpy array\n",
    "X_train_norm = normalizer(X_train).numpy()\n",
    "# Apply same normalization to validation data\n",
    "X_val_norm = normalizer(X_val).numpy() \n",
    "# Apply same normalization to test data\n",
    "X_test_norm = normalizer(X_test).numpy()\n",
    "\n",
    "# Print shapes of all datasets to verify the splitting worked correctly\n",
    "print(\"X_train_norm Shape: \", X_train_norm.shape)\n",
    "print(\"y_train Shape: \", y_train.shape)\n",
    "print(\"X_val_norm Shape: \", X_val_norm.shape)\n",
    "print(\"y_val Shape: \", y_val.shape)\n",
    "print(\"X_test_norm Shape: \", X_test_norm.shape)\n",
    "print(\"y_test Shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f917ded-6b81-4ef2-a3b7-70c90e3909eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Linear Regression model using sklearn\n",
    "# Initialize and train the Linear Regression model\n",
    "sklearn_model = LinearRegression()\n",
    "sklearn_model.fit(X_train_norm, y_train)\n",
    "\n",
    "# Make predictions on validation and test sets\n",
    "val_predictions = sklearn_model.predict(X_val_norm)\n",
    "y_predict_sklearn = sklearn_model.predict(X_test_norm)\n",
    "\n",
    "# Calculate mean squared error for both validation and test sets\n",
    "val_loss = mean_squared_error(y_val, val_predictions)\n",
    "test_loss = mean_squared_error(y_test, y_predict_sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dc3a9d-993b-4e63-9d00-f8611a894387",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Validation MSE: {val_loss:.4f}\")\n",
    "print(f\"Test MSE: {test_loss:.4f}\")\n",
    "\n",
    "# Create a plot comparing actual vs predicted sales\n",
    "utils.plot_predictions(y_test, y_predict_sklearn, 'Predicted vs Actual Sales', 'Actual Sales', 'Predicted Sales')\n",
    "\n",
    "# Print the first 25 actual and predicted values for comparison\n",
    "for i in range(25):\n",
    "    print(\"Print actual vs predicted values\")\n",
    "    print(f\"Actual: {y_test[i]}, Predicted: {y_predict_sklearn[i]:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3dcd77-6221-4d44-92ae-b38b537d3837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Linear Regression model using TensorFlow\n",
    "# Define a simple Sequential model with a Dense layer (1 unit for linear regression)\n",
    "tf_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(X_train_norm.shape[1],)),\n",
    "    tf.keras.layers.Dense(1)  # Linear regression (no activation)\n",
    "])\n",
    "\n",
    "# Display model architecture\n",
    "tf_model.summary()\n",
    "\n",
    "# Configure the model training parameters\n",
    "tf_model.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "    loss='mse', # Mean Squared Error loss\n",
    "    metrics=['mae'] # Track Mean Absolute Error during training\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = tf_model.fit(\n",
    "    X_train_norm, y_train,\n",
    "    validation_data=(X_val_norm, y_val),\n",
    "    epochs=200,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Evaluate on test data\n",
    "test_loss, test_mae = tf_model.evaluate(X_test_norm, y_test, verbose=0)\n",
    "\n",
    "# Generate predictions on test data\n",
    "y_predict_tf = tf_model.predict(X_test_norm).flatten() # Flatten converts 2D array to 1D for easier comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b16facd-c1d4-4034-90bf-a68b026bd320",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Test Loss (MSE): {test_loss:.4f}\")\n",
    "print(f\"Test Mean Absolute Error: {test_mae:.4f}\")\n",
    "\n",
    "# Create a plot comparing actual vs predicted sales\n",
    "utils.plot_predictions(y_test, y_predict_tf, 'Predicted vs Actual Sales', 'Actual Sales', 'Predicted Sales')\n",
    "\n",
    "# Print the first 25 actual and predicted values for comparison\n",
    "for i in range(25):\n",
    "    print(\"Print actual vs predicted values\")\n",
    "    print(f\"Actual: {y_test[i]}, Predicted: {y_predict_tf[i]:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec35a9d-c2d4-4b69-b3ea-7c87222e27a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (johnenv1)",
   "language": "python",
   "name": "johnenv1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
